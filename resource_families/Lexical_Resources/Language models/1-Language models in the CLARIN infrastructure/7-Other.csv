Corpus;Corpus_URL;Size;Annotation;Licence;Licence_URL;Language;Description;Family;Buttons;Buttons_URL;Publication;Publication_URL;Note
Czech Models for Korektor 2;http://hdl.handle.net/11234/1-1460;;normalization;CC BY-NC-SA 3.0;;Czech;"These models are for the statistical spellchecker <a href=""https://ufal.mff.cuni.cz/korektor"">Korektor 2</a>. The models can either perform spellchecking and grammar-checking, or only generate diacritical marks.#SEPThe models are available for download from the LINDAT repository.";Language models;Download;http://hdl.handle.net/11234/1-1460;;;
Sentiment Analysis (Czech Model);http://hdl.handle.net/11234/1-4601;;sentiment analysis;CC BY-NC-SA 4.0;;Czech;"These models are trained on data from the following sources: Mall (product reviews), CSFD (movie reviews), and Facebook, and joint data from all three datasets above (data available <a href=""http://liks.fav.zcu.cz/sentiment/"">here</a>, using <a href=""https://arxiv.org/abs/2105.11314"">RobeCzech</a>, which is the Czech version of BERT.";Language models;Download;http://hdl.handle.net/11234/1-4601;Vysušilová (2021);http://hdl.handle.net/20.500.11956/147648;
"
Model weights for a study of commonsense reasoning";https://hdl.handle.net/21.11129/0000-000F-4869-B;;commonsense reasoning;MIT;;English;"This resource contains model weights for five Transformer-based models: <a href=""https://huggingface.co/docs/transformers/model_doc/roberta"">roBERTa</a>, <a href=""https://huggingface.co/docs/transformers/model_doc/gpt2"">GPT-2</a>, <a href=""https://huggingface.co/docs/transformers/model_doc/t5"">T5</a>, <a href=""https://huggingface.co/docs/transformers/model_doc/bart"">BART</a> and <a href=""https://aclanthology.org/P19-1470/"">COMET</a>.These models were implemented using <a href=""https://huggingface.co/"">HuggingFace</a>, and fine-tuned on the following four commonsense reasoning tasks: Argument Reasoning Comprehension Task (ARCT), AI2 Reasoning Challenge (ARC), Physical Interaction Question Answering (PIQA) and CommonsenseQA (CSQA).#SEPThe models are available for download form the PORTULAN repository.";Language models;Download;https://hdl.handle.net/21.11129/0000-000F-4869-B;;;
RÚV-DI Speaker Diarization v5 models (21.05);http://hdl.handle.net/20.500.12537/109;;diarization;CC BY 4.0;;Icelandic;"These models are trained on the <a href=""https://clarin.is/en/resources/althingisgognin/"">Althingi Parliamentary Speech</a> corpus hosted by CLARIN-IS.  The models use MFCCS, x-vectors, PLDA and AHC#SEPThe models are available for download from the CLARIN-IS repository.";Language models;Download;http://hdl.handle.net/20.500.12537/109;;;
Models for automatic g2p for Icelandic (20.10);http://hdl.handle.net/20.500.12537/84;;phonemic transcription;Apache License 2.0;;Icelandic;"These are grapheme-to-phoneme models for Icelandic, trained on an encoder-decoder <a href=""https://en.wikipedia.org/wiki/Long_short-term_memory"">LSTM</a> neural network. The models are delivered with scripts for automatic transcription of Icelandic in the standard pronunciation variation, in the northern variation, north-east variation, and the south variation. To run the scripts the user needs to install <a href=""https://github.com/grammatek/g2p-lstm"">Fairseq</a>.";Language models;Download;http://hdl.handle.net/20.500.12537/84;Gorman et al. (2020);https://www.aclweb.org/anthology/2020.sigmorphon-1.2/;
Liner2.5 model Timex;http://hdl.handle.net/11321/302;;temporal expressions;CC BY-SA 4.0;;Polish;"This is a model for the <a href=""https://github.com/CLARIN-PL/Liner2"">Liner2.5</a> tool for the recognition and normalization on temporal expressions.#SEPThe model is available for download from the CLARIN-PL repository.";Language models;Download;http://hdl.handle.net/11321/302;;;
Liner2.5 model Events;http://hdl.handle.net/11321/301;;event mentions;CC BY-SA 4.0;;Polish;"This is a model for the <a href=""https://github.com/CLARIN-PL/Liner2"">Liner2.5</a> tool for the recognition of event mentions.#SEPThe model is available for download from the CLARIN-PL repository.";Language models;Download;http://hdl.handle.net/11321/301;;;
PyTorch model for Slovenian Coreference Resolution;http://hdl.handle.net/11356/1773;;coreference resolution;CC BY 4.0;;Slovenian;"This is a Slovenian model for coreference resolution: a neural network based on a customized transformer architecture, usable with <a href=""https://github.com/matejklemen/slovene-coreference-resolution"">this code</a>. The model is based on the <a href=""http://hdl.handle.net/11356/1330"">Slovenian CroSloEngual BERT 1.1 model</a>. It was trained on the <a href=""http://hdl.handle.net/11356/1747"">SUK 1.0 training corpus</a>, specifically the SentiCoref subcorpus.#SEPThis resource is available for download from the CLARIN.SI repository.";Language models;Download;http://hdl.handle.net/11356/1773;Klemen & Žitnik (2022);https://doi.org/10.2298/CSIS201120060K;
Face-domain-specific automatic speech recognition models;http://hdl.handle.net/11356/1749;;face-domain-specific automatic speech recognition;Apache License 2.0;;Slovenian;"This model contains all the files required to implement face-domain-specific automatic speech recognition (ASR) applications using the <a href=""https://github.com/kaldi-asr/kaldi"">Kaldi ASR toolkit</a>, including the acoustic model, language model, and other relevant files. It also includes all the scripts and configuration files needed to use these models for implementing face-domain-specific automatic speech recognition.#SEPThe acoustic model was trained using the relevant Kaldi ASR tools and the Artur speech corpus (<a href=""http://hdl.handle.net/11356/1776"">audio</a>,<a href=""http://hdl.handle.net/11356/1772"">transcriptions</a>). The language model was trained using the domain-specific text data involving face descriptions obtained by translating the <a href=""https://github.com/mtanti/face2text-dataset""> Face2Text English dataset </a> into the Slovenian language. These models, combined with other necessary files like the HCLG.fst and decoding scripts, enable the implementation of face-domain-specific ASR applications.#SEPThis resource is available for download from the CLARIN.SI repository.";Language models;Download;http://hdl.handle.net/11356/1749;;;
The CLASSLA-Stanza model for semantic role labeling of standard Slovenian 2.0;http://hdl.handle.net/11356/1770;;semantic role labeling;CC BY-SA 4.0;;Slovenian;"The model for lemmatisation of standard Slovenian was built with the <a href=""https://github.com/clarinsi/classla"">CLASSLA-Stanza tool</a> by training on the <a href=""http://hdl.handle.net/11356/1747"">SUK training corpus</a> and using the <a href=""http://hdl.handle.net/11356/1204"">CLARIN.SI-embed.sl word embeddings</a> extended with the <a href=""http://hdl.handle.net/11356/1517"">MaCoCu-sl Slovene web corpus</a>. The estimated F1 of the lemma annotations is ~76.24.#SEPThe model is available for download from the CLARIN.SI repository.";Language models;Download;http://hdl.handle.net/11356/1770;Ljubešić & Dobrovoljc (2019);http://dx.doi.org/10.18653/v1/W19-3704;
