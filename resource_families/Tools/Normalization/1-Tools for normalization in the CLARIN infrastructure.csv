"Tool";"Tool_URL";"Functionality";"Domain";"Licence";"Licence_URL";"Language";"Description";"Family";"Buttons";"Buttons_URL";"CLARIN_Centre";"Platform";"Input_format";"Output_format";"Publication";"Publication_URL";"Note"
"Text Tonsorium";"http://portal.clarin.nl/node/19258";"tokenization, segmentation, lemmatization, PoS-tagging, normalization, syntax analysis, NER, format transformations";"independent";"GPL";;"Afrikaans, Albanian, Armenian, Basque, Bosnian, Breton, Bulgarian, Catalan, Chinese, Corsican, Croatian, Czech, Danish, Dutch, English, Esperanto, Estonian, Faroese, Finnish, French, Galician, Georgian, German, Greek, Middle Low German, Haitian, Hindi, Hungarian, Icelandic, Indonesian, Inuktitut, Irish, Italian, Javanese, Kannada, Kurdish, Latin, Latvian, Lithuanian, Luxembourgish, Macedonian, Malay, Malayalam, Maltese, Norwegian, Occitan, Persian, Polish, Portuguese, Romanian, Russian, Serbian, Slovak, Slovenian, Spanish, Swahili, Swedish, Tamil, Turkish, Ukranian, Uzbek, Vietnamese, Welsh, Yiddish";"Automatic construction and execution of several NLP workflows, which include normalisation.";"Normalization";"download#SEPweb application";"http://github.com/kuhumcst/texton#SEPhttps://cst.dk/WMS/";"CLARIN-DK";"Ubuntu";;;;;
"Korektor";"http://lindat.cz/services/korektor/";"normalization";;"CC-BY-NC-A (models)";;"Czech";"Korektor is a statistical spellchecker and (occasional) grammar checker released under <a href=""http://opensource.org/licenses/BSD-2-Clause"">2-Clause BSD license</a> and versioned using <a href=""http://semver.org/"">Semantic Versioning</a>.#SEPKorektor started with Michal Richter's diploma thesis <a href=""https://redmine.ms.mff.cuni.cz/documents/1"">Advanced Czech Spellchecker</a>, but it is being developed further. There are two versions: a command line utility (tested on Linux, Windows and OS X) and a REST service with <a href=""https://lindat.mff.cuni.cz/services/korektor/api-reference.php"">publicly available API</a> and <a href=""https://lindat.mff.cuni.cz/services/korektor/"">HTML front end</a>.";"Normalization";"web service#SEPAPI";"https://lindat.mff.cuni.cz/services/korektor/#SEPhttps://lindat.mff.cuni.cz/services/korektor/api-reference.php";"LINDAT";"Linux, Windows, OS X";"plain text";"enriched text";"Richter et al. (2012)";"https://www.clarin.eu/resource-families/tools-normalisation#Richter%20et%20al.%202012";
"FoLiA-wordtranslate";"https://github.com/LanguageMachines/foliautils";"normalization";"historical texts";"GNU Public License v3";;"Dutch";"This tool does word-by-word lookups in a bilingual lexicon, applies some transformation rules and additionally it may consult the INT Historical Lexicon (to be obtained separately due to licensing restrictions). The aim is to use the modernisation layer to do further linguistic enrichment using contemporary models. This tool is part of the FoLiA-Utils collection as it operates on documents in the FoLiA format. Standalone it is only of very limited interest to others.";"Normalization";"download";"https://metacpan.org/release/DTA-CAB";"CLARIAH-NL";"Linux/POSIX (C++)";"plain text, FoLiA-XML";"FoLiA-XML, plaintext";;;
"Nederlab Pipeline";"https://github.com/proycon/nederlab-pipeline";"modernisation, normalisation, tokenisation, conversion, PoS-tagging, lemmatisation, NER with entity linking (all functionality is derived from the individual parts rather than an inherent part of the workflow)";"independent";"GNU Public License v3";;"Dutch";"This is a linguistic enrichment pipeline for Historical Dutch as developed for and used in the <a href=""https://www.nederlab.nl/"">Nederlab project</a>. This workflow, powered by <a href=""https://www.nextflow.io/"">Nextflow</a>, invokes various tools, including <a href=""https://languagemachines.github.io/frog"">Frog</a> and <a href=""https://github.com/LanguageMachines/piccl"">FoLiA-wordtranslate</a>, as well as other tools such as <a href=""https://languagemachines.github.io/ucto"">ucto</a> (a tokeniser), <a href=""https://github.com/proycon/foliatools"">folialangid</a> (language identification), <a href=""https://github.com/proycon/foliatools"">tei2folia</a> (conversion from a subset of TEI to FoLiA, which serves as the exchange format for all our tooling, as well as the final corpus format for Nederlab). Due to the high complexity in tooling, this workflow and all dependencies are distributed as part of the <a href=""https://proycon.github.io/LaMachine"">LaMachine</a> distribution.";"Normalization";"download";"https://github.com/proycon/nederlab-pipeline/";"CLARIAH-NL";"Linux/POSIX (workflow itself runs on JVM, underlying components are mostly implemented in C++ and Python)";"FoLiA XML";"FoLiA XML";"Brugman et al. (2016)";"https://www.clarin.eu/resource-families/tools-normalization#Brugman%20et%20al.%202016";
"TiCClops";"https://portal.clarin.nl/node/14376";"corpus processing, normalization";"independent";;;"Dutch";"This tool is designed to search a corpus for all existing variants of (potentially) all words occurring in the corpus. This corpus can be one text, or several, in one or more directories, located on one or more machines. TICCL creates word frequency lists, listing for each word type how often the word occurs in the corpus. These frequencies of the normalized word forms are the sum of the frequencies of the actual word forms found in the corpus.#SEPTICCL is a system that is intended to detect and correct typographical errors (misprints) and OCR errors (optical character recognition) in texts. When books or other texts are scanned from paper by a machine, that then turns these scans, i.e. images, into digital text files, errors occur. For instance, the letter combination `in' can be read as `m', and so the word `regeering' is incorrectly reproduced as `regeermg'. TICCL can be used to detect these errors and to suggest a correct form.";"Normalization";;;"CLARIAH-NL";"cross-platform";"images (tiff, djvu), plain text, xml, csv";"xml";"Reynaert (2010)";"https://www.clarin.eu/resource-families/tools-normalization#Reynaert%202010";
"@Philostei";"https://portal.clarin.nl/node/14367";"corpus processing, normalization";"independent";;;"Dutch, English, Finnish, French, German, German (Fraktur), Classical Greek, Modern Greek, Icelandic, Italian, Latin, Polish, Portuguese, Russian, Spanish, Swedish";"This tool uses a combination of a <a href=""https://opensource.google/projects/tesseract"">Tesseract</a> webservice for text layout analysis and OCR and a multilingual version of <a href=""https://portal.clarin.nl/node/14376"">TICCL</a> for normalization.";"Normalization";;;"CLARIAH-NL";"cross-platform";"images (tiff, djvu), plain text, XML, csv";"XML";"Betti, Reynaert and van den Berg (2017)";"https://www.clarin.eu/resource-families/tools-normalization#Betti%20et%20al.%202017";
"PICCL: Philosophical Integrator of Computational and Corpus Libraries";"https://portal.clarin.nl/node/14392";"OCR, normalization, tokenisation, dependency parsing, shallow parsing, lemmatization, morphological analysis, NER, PoS-tagging";"independent";"GNU GPL";;"Dutch, Swedish, Russian, Spanish, Portuguese, English, German, French, Italian, Finnish, Modern Greek, Classical Greek, Icelandic, German (Fraktur), Latin, Romanian";"This is a set of workflows for corpus building through OCR, post-correction, modernization of historic language and Natural Language Processing. It combines <a href=""https://opensource.google/projects/tesseract"">Tesseract Optical Character Recognition</a>, <a href=""https://portal.clarin.nl/node/14376"">TICCL</a> and <a href=""https://languagemachines.github.io/frog"">FROG</a> functionality in a single pipeline.";"Normalization";"download";"https://github.com/LanguageMachines/piccl";"CLARIAH-NL";"cross-platform";"images (tiff, vnd.djvu), plain text, xml";"FoLiA XML";"Reynaert et al. (2015)";"https://www.clarin.eu/resource-families/tools-normalization#Reynaert%20et%20al.%202015";
"VARD2";"http://ucrel.lancs.ac.uk/vard/about/";"normalization";"historical texts";"CC-BY-NC-SA 2.0";;"English";"This tool performs manual and automatic spelling normalisation based on letter replacement rules, phonetic matching (extended Soundex), edit distance, and variant mappings.";"Normalization";"download";"http://ucrel.lancs.ac.uk/vard/availability/";"CLARIAH-UK";"cross-platform (java)";"plain text, rtf, SGML, XML";"XML";"see here";"http://ucrel.lancs.ac.uk/vard/publications/";
"CAB historical text analysis";"http://hdl.handle.net/21.11120/0000-0003-7D99-5";"normalisation, PoS-tagging, lemmatisation";"historical texts";;;"German";"This tool is a WebLicht stub for the <a href=""http://odo.dwds.de/~jurish/software/DTA-CAB/"">DTA::CAB</a> service and provides orthographic normalisation, PoS-tagging and lemmatization for historical German.";"Normalization";"web application";"https://www.deutschestextarchiv.de/public/cab/?fmt=tcf";"CLARIN-D";"cross-platform";"plain text, XML";"<a href=""https://universaldependencies.org/tagset-conversion/de-stts-uposf.html"">stts</a> tagset for PoS";;;
"CAB orthographic canonicalizer";"http://hdl.handle.net/11858/00-203C-0000-0023-21BB-3";"normalisation";"historical texts";;;"German";"This tool a WebLicht stub for the <a href=""http://odo.dwds.de/~jurish/software/DTA-CAB/"">DTA::CAB</a> service and provides orthographic normalization for historical German.";"Normalization";"web application";"https://www.deutschestextarchiv.de/public/cab/?fmt=tcf-orth";"CLARIN-D";"cross-platform";"plain text, XML";"unspecified";;;
"DTA::CAB";"http://odo.dwds.de/~jurish/software/DTA-CAB/";"lemmatization, PoS-tagging, normalization";"historical texts";"TOS";"https://metacpan.org/pod/DTA::CAB#COPYRIGHT-AND-LICENSE";"German";"This is an abstract framework for robust linguistic annotation, with public web-service including normalization and lemmatization for historical German";"Normalization";"download#SEPweb application";"https://metacpan.org/release/DTA-CAB#SEPhttps://www.deutschestextarchiv.de/public/cab/";"CLARIN-D";"cross-platform";"<a href=""http://odo.dwds.de/~jurish/software/DTA-CAB/doc/html/DTA.CAB.WebServiceHowto.html#I-O-Formats"">various</a>";"<a href=""http://odo.dwds.de/~jurish/software/DTA-CAB/doc/html/DTA.CAB.WebServiceHowto.html#I-O-Formats"">various</a>";"Jurish (2012)";"https://www.clarin.eu/resource-families/tools-normalization#Jurish%202012";
"Normo";;"normalization";"historical texts";;;"Hungarian";"This tool is an automatic pre-normalizer for Middle Hungarian Bible translations. It employs a memory-based and a rule-based module, which consists of character- and token level rewrite rules. The tool was used for building the <a href=""http://oldhungariancorpus.nytud.hu/"">Old Hungarian Corpus</a>.";"Normalization";;;"HUN-CLARIN";;"unspecified";"unspecified";"Vadász and Simon (2018)";"https://www.clarin.eu/resource-families/tools-normalization#Vad%C3%A1sz%20and%20Simon%202018";
"Skrambi";"https://notendur.hi.is/~kristinb/clarin-2015-6okt.pdf";"OCR, normalization";"historical texts";;;"Icelandic";"This tool is a spell-checking application based on a noisy channel model, which can be used to achieve a true copy of the original spelling of historical OCR texts, and to produce a parallel text with modern spelling.";"Normalization";;;"CLARIN-IS";;"unspecified";"unspecified";;;
"CSMTiser";"https://github.com/clarinsi/csmtiser";"normalization";"social media";"GNU Lesser General Public License v3.0";;"Slovenian";"This is a trainable tool for text normalisation, based on <a href=""http://www.statmt.org/moses/"">Moses</a>.";"Normalization";"download";"https://github.com/clarinsi/csmtiser";"CLARIN.SI";"Linux";"unspecified";"unspecified";"Ljubešić et al. (2016)";"https://www.clarin.eu/resource-families/tools-normalization#Ljube%C5%A1i%C4%87%20et%20al.%202015";
"Turkish Natural Language Processing Pipeline";"https://hdl.handle.net/11372/LRT-712";"tokenisation, sentence splitting, normalisation,de-asciification, vowelisation, spelling correction, morphological analysis/disambiguation, named entity recognition, dependency parsing";"independent";;;"Turkish";"This is a pipeline of state-of-the-art Turkish NLP tools.";"Normalization";"web application#SEPweb API";"http://tools.nlp.itu.edu.tr/Normalization#SEPhttp://tools.nlp.itu.edu.tr/api_usage.jsp";"LINDAT";"cross-platform";"plain text";"plain text";"Eryiğit (2014)";"https://www.clarin.eu/resource-families/tools-normalization#Eryi%C4%9Fit%202014";
