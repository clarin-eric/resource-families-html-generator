<h2 id="1-Corpora-of-disordered-speech-in-the-CLARIN-infrastructure">Corpora of disordered speech in the CLARIN infrastructure</h2>
<h3 id"table-title">CSD</h3>
<table class ="table" cellspacing="5">
	<thead>
		<tr>
			<th valign="top">Corpus
			</th>
			<th valign="top">Language
			</th>
			<th valign="top">Description
			</th>
			<th valign="top">Availability
			</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://aphasia.talkbank.org/">AphasiaBank</a>
				</p>
				<p>
					<strong>Size: </strong>380 MB transcripts, 827 GB media
					<br>
					<strong>Annotation: </strong>CHAT and CA/CHAT
					<br>
					<strong>Licence: </strong>email request for access
				</p>
			</td>
			<td valign="top">
				Cantonese, Croatian, English, French, German, Greek, Hungarian, Italian, Japanese, Mandarin, Romanian, Spanish
			</td>
			<td valign="top">
				<p>This is a corpus of multimedia interactions for the study of communication in aphasia.</p>
<p> Access to the data in AphasiaBank is password protected and restricted to members of the AphasiaBank consortium group. </p>
<p>Data in TalkBank use a consistent XML-compatible representation called CHAT. All of the data is transcribed in CHAT and CA/CHAT formats.</p>

				
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://sla.talkbank.org/TBB/aphasia"><span class="fa fa-search"></span>Browse</a></p>

				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="http://hdl.handle.net/11356/1435">Croatian corpus of non-professional written language by typical speakers and speakers with language disorders RAPUT 1.0</a>
				</p>
				<p>
					<strong>Size: </strong>6760 texts, 34469 sentences, 426187 tokens
					<br>
					<strong>Annotation: </strong>MULTEXT-East tagset
					<br>
					<strong>Licence: </strong>CC-BY-SA 4.0
				</p>
			</td>
			<td valign="top">
				Croatian
			</td>
			<td valign="top">
				<p>The corpus consists of texts produced by nonprofessional typical speakers and speakers with different language disorders (developmental language disorder, dyslexia, traumatic brain injury, aphasia, other).</p>
<p>Roughly half of the corpus consists of texts of typical speakers, and the other half of speakers with language disorders.</p>
<p>Language samples were elicited by six groups of tasks representing different writing styles (descriptive, expository, narrative, and letter) and different levels of formality.</p>

				<p>For the relevant publication, see <a href="https://hrcak.srce.hr/file/370152">Kuvač Kraljević et al. (2021)</a></p>
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="http://hdl.handle.net/11356/1435"><span class="fa fa-arrow-circle-o-down"></span>Download</a></p>

				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://hdl.handle.net/1839/00-2766F32F-4305-4F13-A02C-F4A8F5216425">ADHD and SLI corpus UvA database</a>
				</p>
				<p>
					<strong>Size: </strong>4 GB (67 recordings) of 26 Dutch children with ADHD, 19 Dutch children with SLI, 22 children Dutch controls
					<br>
					<strong>Annotation: </strong>Transcriptions (CHAT-format)
					<br>
					<strong>Licence: </strong>CLARIN PUB (Transcriptions), CLARIN RESTRICTED (Recordings)
				</p>
			</td>
			<td valign="top">
				Dutch
			</td>
			<td valign="top">
				<p>This corpus aims to compare the language and executive functioning profiles of children with ADHD to children with Specific Language Impairment and children with Tourette’s Disorder.</p>

				
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://hdl.handle.net/1839/00-2766F32F-4305-4F13-A02C-F4A8F5216425"><span class="fa fa-arrow-circle-o-down"></span>Download</a></p>

				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://hdl.handle.net/1839/00-F6BC06C4-B2AD-4ED8-8527-AB81F4EF4E8F">Bilingual deaf children RU-Kentalis database</a>
				</p>
				<p>
					<strong>Size: </strong>4 GB complete video recordings. 1 GB selected parts video recordings. 0,1 GB selected parts transcripts. 0,5 GB test and background data of 11 deaf children, longitudinal, 104 recordings
					<br>
					<strong>Annotation: </strong> CHAT-like format for 104 recordings
					<br>
					<strong>Licence: </strong>CLARIN PUB (Transcriptions), CLARIN RESTRICTED (Recordings)
				</p>
			</td>
			<td valign="top">
				Dutch
			</td>
			<td valign="top">
				<p>The corpus is used for investigating the bilingual language and communication development of young deaf children in Sign Language of the Netherlands (SLN) and Dutch.</p>

				<p>For the relevant publication, see <a href="https://doi.org/10.1093/deafed/enj032">Klatter-Folmer et al. (2016)</a></p>
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://hdl.handle.net/1839/00-F6BC06C4-B2AD-4ED8-8527-AB81F4EF4E8F"><span class="fa fa-arrow-circle-o-down"></span>Download</a></p>

				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://hdl.handle.net/1839/00-97AF29EA-877D-422A-BAF7-25FA269351A6">SLI RU-Kentalis database</a>
				</p>
				<p>
					<strong>Size: </strong>2 GB
					<br>
					<strong>Annotation: </strong>Praat transcripts
					<br>
					<strong>Licence: </strong>CLARIN PUB (Transcriptions), CLARIN RESTRICTED (Recordings)
				</p>
			</td>
			<td valign="top">
				Dutch
			</td>
			<td valign="top">
				<p>The corpus has been collected to investigate of the expression of spatial relations by children with SLI and normally developing children in their spoken language production. </p>

				
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://hdl.handle.net/1839/00-712802F3-C245-4EF0-BE9D-D09714DEDE67"><span class="fa fa-arrow-circle-o-down"></span>Download</a></p>

				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="http://hdl.handle.net/10032/tm-a2-n3">Dutch Corpus of Pathological and Normal Speech (COPAS) </a>
				</p>
				<p>
					<strong>Size: </strong>319 speakers of which 122 normal controls and 197 with a speech disorder. Corpus size: 1.3 GB
					<br>
					<strong>Annotation: </strong>Orthographic transcription
					<br>
					<strong>Licence: </strong>Academic, bespoke
				</p>
			</td>
			<td valign="top">
				Dutch (Flemish)
			</td>
			<td valign="top">
				<p>This corpus has been constructed within the framework of the project Speech Algorithms for Clinical and Educational applications (SPACE).</p>

				<p>For the relevant publication, see <a href="http://hdl.handle.net/1854/LU-1053399">Middag et al. (2010)</a></p>
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="http://hdl.handle.net/10032/tm-a2-n3"><span class="fa fa-arrow-circle-o-down"></span>Download</a></p>

				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://fluency.talkbank.org/">FluencyBank</a>
				</p>
				<p>
					<strong>Size: </strong>481 MB transcripts, 207 GB media
					<br>
					<strong>Annotation: </strong>CHAT and CA/CHAT
					<br>
					<strong>Licence: </strong>email request for access
				</p>
			</td>
			<td valign="top">
				Dutch, English, French, German
			</td>
			<td valign="top">
				<p>This corpus is intended for the study of fluency development.</p>
<p>Participants include typically-developing monolingual and bilingual children, children and adults who stutter (C/AWS) or who clutter (C/AWC), and second language learners.</p>
<p>Access to the research data in FluencyBank is password protected and restricted to members of the FluencyBank consortium group, although a subset of the corpus is publicly available.</p>
<p>Data in TalkBank use a consistent XML-compatible representation called CHAT. All of the data is transcribed in CHAT and CA/CHAT formats.</p>

				
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://sla.talkbank.org/TBB/fluency"><span class="fa fa-search"></span>Browse</a></p>

				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://asd.talkbank.org/">ASDBank</a>
				</p>
				<p>
					<strong>Size: </strong>42 MB transcripts, 401 MB media
					<br>
					<strong>Annotation: </strong>CHAT and CA/CHAT
					<br>
					<strong>Licence: </strong>open access
				</p>
			</td>
			<td valign="top">
				Dutch, English, French, Greek, Mandarin, Spanish
			</td>
			<td valign="top">
				<p>This is a corpus of multimedia interactions for the study of communication in autism-spectrum disorder.</p>
<p>Data in TalkBank use a consistent XML-compatible representation called CHAT. All of the data is transcribed in CHAT and CA/CHAT formats.</p>

				
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://sla.talkbank.org/TBB/asd"><span class="fa fa-search"></span>Browse</a></p>

				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://hdl.handle.net/1839/00-97AF29EA-877D-422A-BAF7-25FA269351A6">Deaf adults RU database</a>
				</p>
				<p>
					<strong>Size: </strong>2GB of 46 deaf Dutch adults, 38 hearing Turkish adults, 24 hearing Moroccan adults, 10 Dutch controls
					<br>
					<strong>Licence: </strong>CLARIN PUB (Transcriptions), CLARIN RESTRICTED (Recordings)
				</p>
			</td>
			<td valign="top">
				Dutch, Turkish, Moroccan
			</td>
			<td valign="top">
				<p>This corpus aims at the investigation of the acquisition of Dutch by deaf Dutch adults (late L1/early L2) and comparison to hearing Turkish and Moroccan-Arabic.</p>

				<p>For the relevant publication, see <a href="https://pure.uva.nl/ws/files/1840998/113644_thesis.pdf">Parriger (2012)</a></p>
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://hdl.handle.net/1839/00-97AF29EA-877D-422A-BAF7-25FA269351A6"><span class="fa fa-arrow-circle-o-down"></span>Download</a></p>

				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://tbi.talkbank.org/">TBIBank</a>
				</p>
				<p>
					<strong>Size: </strong>63 MB transcripts, 98 GB media
					<br>
					<strong>Annotation: </strong>CHAT and CA/CHAT
					<br>
					<strong>Licence: </strong>email request for access
				</p>
			</td>
			<td valign="top">
				English
			</td>
			<td valign="top">
				<p>This is a corpus of multimedia interactions for the study of communication in people with traumatic brain injury.</p>
<p>Access to the data in TBIBank is password protected and restricted to members of the TBIBank consortium group.</p>
<p>Data in TalkBank use a consistent XML-compatible representation called CHAT. All of the data is transcribed in CHAT and CA/CHAT formats.</p>

				
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://sla.talkbank.org/TBB/tbi"><span class="fa fa-search"></span>Browse</a></p>

				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://psychosis.talkbank.org/">PsychosisBank</a>
				</p>
				<p>
					<strong>Size: </strong>Not available
					<br>
					<strong>Annotation: </strong>CHAT and CA/CHAT
					<br>
					<strong>Licence: </strong>email request for access
				</p>
			</td>
			<td valign="top">
				English (various dialects), Spanish
			</td>
			<td valign="top">
				<p>This is a corpus intended for the study of language in psychosis.</p>
<p>The site is noted as under construction.</p>
<p>Data in TalkBank use a consistent XML-compatible representation called CHAT. All of the data is transcribed in CHAT and CA/CHAT formats.</p>

				
			</td>
			<td valign="top">
				
				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://sla.talkbank.org/TBB/dementia">Alzheimer's Dementia Recognition through Spontaneous Speech (audio only): The ADReSSo Challenge</a>
				</p>
				<p>
					<strong>Annotation: </strong>CHAT and CA/CHAT 
					<br>
					<strong>Licence: </strong>email request for access
				</p>
			</td>
			<td valign="top">
				English, German, Mandarin, Spanish, Taiwanese
			</td>
			<td valign="top">
				<p>This is a corpus of multimedia interactions for the study of communication in dementia.</p>
<p>Access to the data in DementiaBank is password protected and restricted to members of the DementiaBank consortium group.</p>
<p>Data in TalkBank use a consistent XML-compatible representation called CHAT. All of the data is transcribed in CHAT and CA/CHAT formats.</p>

				
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://sla.talkbank.org/TBB/dementia"><span class="fa fa-search"></span>Browse</a></p>

				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://rhd.talkbank.org/">RHDBank</a>
				</p>
				<p>
					<strong>Size: </strong>30 MB transcripts, 28 GB media
					<br>
					<strong>Annotation: </strong>CHAT and CA/CHAT
					<br>
					<strong>Licence: </strong>email request for access
				</p>
			</td>
			<td valign="top">
				English, Spanish
			</td>
			<td valign="top">
				<p>This is a corpus of multimedia interactions for the study of communication in people with Right Hemisphere Damage (RHD).</p>
<p>Access to the data in RHDBank is password protected and restricted to members of the RHDBank consortium group.</p>
<p>Data in TalkBank use a consistent XML-compatible representation called CHAT. All of the data is transcribed in CHAT and CA/CHAT formats.</p>

				
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://sla.talkbank.org/TBB/rhd"><span class="fa fa-search"></span>Browse</a></p>

				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="http://hdl.handle.net/20.500.11752/OPEN-989">DemCorpus-Basilicata: Dementia Corpus</a>
				</p>
				<p>
					<strong>Size: </strong>08:50 hours
					<br>
					<strong>Licence: </strong>Processed data available by request
				</p>
			</td>
			<td valign="top">
				Italian
			</td>
			<td valign="top">
				<p>This corpus consists of semi-spontaneous speech data produced by elderly residents of the Basilicata region in Italy.</p>
<p>In total, 40 individuals participated: the patient group consists of 20 participants with a diagnosis of dementia (9 cases of Alzheimer’s disease, 2 patients with mixed dementia, 5 patients with not-further-specified dementia, 3 patients with vascular dementia, and 1 patient with frontotemporal dementia).</p>
<p>the control group consists of 20 healthy individuals matched for age, gender, and geographical origin. Three linguistic tasks were administered to all participants: two narrative tasks (the first one was about an excursion or a trip, and the second was about Christmas festivities), and an image description task. This resulted in 8 hours and 50 minutes of recorded semi-spontaneous speech, which was then transcribed, segmented, and annotated using ELAN. </p>

				<p>For the relevant publication, see <a href="http://hdl.handle.net/20.500.11752/OPEN-989">Martinelli et al. (2022)</a></p>
			</td>
			<td valign="top">
				
				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="http://hdl.handle.net/20.500.11752/OPEN-990">ItaASD: Italian speech corpus Austism Spectrum Disorder</a>
				</p>
				<p>
					<strong>Size: </strong>04.19 hours
					<br>
					<strong>Annotation: </strong>Orthographic
				</p>
			</td>
			<td valign="top">
				Italian
			</td>
			<td valign="top">
				<p>This is a corpus of semi-spontaneous speech produced by 34 children between 6 and 13 years of age, residents in the Campania region of Italy.#sepHalf of the participating children were diagnosed with high-functioning Autism Spectrum Disorder, and the other half were neurotypical children matched for age, gender, and geographical origin.</p>
<p>All participants were administered three tasks: a complex image description task, a story-telling task, and a story-retelling task. This resulted in 4 hours and 19 minutes of recorded speech, which were then transcribed and annotated using ELAN. </p>

				
			</td>
			<td valign="top">
				
				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="http://hdl.handle.net/20.500.11752/ILC-992">OPLON: Opportunities for active and healthy LONgevity</a>
				</p>
				<p>
					<strong>Size: </strong>06:50 hours
				</p>
			</td>
			<td valign="top">
				Italian
			</td>
			<td valign="top">
				<p>This corpus consists of semi-spontaneous speech data collected from 96 elderly participants who were divided into two groups: the pathological and the control group.</p>
<p>The pathological group refers to three categories: (i) 16 participants with amnestic Mild Cognitive Impairment (MCI), (ii) 16 participants with multiple-domain MCI, and (iii) 16 participants with Early Dementia (probable Alzheimer Dementia, Fronto-Temporal Dementia, Mixed Dementia, and Lewy Body Dementia).</p>
<p>The control group includes 48 healthy individuals matched for gender, age, educational level, and geographical origin. The corpus was subjected to PoS Tagging and Dependency Parsing (CoNLL format). </p>

				
			</td>
			<td valign="top">
				
				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://hdl.handle.net/1839/dbcd8568-d17d-4861-94bb-aa553e943399">Polish Cued Speech Corpus of Hearing-Impaired Children</a>
				</p>
				<p>
					<strong>Size: </strong>20 children (11 girls and 9 boys)
					<br>
					<strong>Annotation: </strong>CHAT format
					<br>
					<strong>Licence: </strong>open access or through email request for access
				</p>
			</td>
			<td valign="top">
				Polish
			</td>
			<td valign="top">
				<p>This is a corpus of recordings of the DIA (Dutch Intelligibilty Assessment).</p>
<p>The corpus also contains a variety of other samples like reading passages, isolated sentences and recordings of spontaneous speech.</p>
<p>The corpus contains samples of 187 speakers with a speech disorder and samples of 122 speakers without a speech disorder. </p>

				
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://hdl.handle.net/1839/dbcd8568-d17d-4861-94bb-aa553e943399"><span class="fa fa-arrow-circle-o-down"></span>Download</a></p>

				<p>CLARIN</p>
			</td>
		</tr>
	</tbody>
</table>
<h2 id="2-Other-corpora-of-disordered-speech">Other corpora of disordered speech</h2>
<h3 id"table-title">CSD</h3>
<table class ="table" cellspacing="5">
	<thead>
		<tr>
			<th valign="top">Corpus
			</th>
			<th valign="top">Language
			</th>
			<th valign="top">Description
			</th>
			<th valign="top">Availability
			</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://data.mendeley.com/datasets/9dz247gnyb/4">Perceptual Voice Qualities Database</a>
				</p>
				<p>
					<strong>Size: </strong>296 audio files of varying sizes
					<br>
					<strong>Licence: </strong>CC 4.0
				</p>
			</td>
			<td valign="top">
				English
			</td>
			<td valign="top">
				<p>This corpus contains voice samples which have been rated by experienced voice professionals (at least 3 different raters with a minimum of 2 years’ clinical experience) in order to provide educators with standardized materials to better train pre-service clinical voice professionals. </p>

				<p>For the relevant publication, see <a href="https://pubs.asha.org/doi/10.1044/vvd17.2.11">Kempster (2007)</a></p>
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://data.mendeley.com/datasets/9dz247gnyb/4"><span class="fa fa-search"></span>Browse or download</a></p>

				<p>Other</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="http://www.cs.toronto.edu/~complingweb/data/TORGO/torgo.html">TORGO</a>
				</p>
				<p>
					<strong>Size: </strong>Originally TORGO database contains 18GB of data
					<br>
					<strong>Licence: </strong>CC-BY
				</p>
			</td>
			<td valign="top">
				English
			</td>
			<td valign="top">
				<p>This is a corpus of dysarthric articulation and consists of aligned acoustics and measured 3D articulatory features from speakers with either cerebral palsy (CP) or amyotrophic lateral sclerosis (ALS), which are two of the most prevalent causes of speech disability, and matched controls.</p>
<p>This dataset contains 2000 samples for dysarthric males, dysarthric females, non-dysarthric males, and non-dysarthric females.</p>

				<p>For the relevant publication, see <a href="https://doi.org/10.1007/s10579-011-9145-0">Rudzicz et al. (2012)</a></p>
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="http://www.cs.toronto.edu/~complingweb/data/TORGO/torgo.html"><span class="fa fa-search"></span>Browse</a></p>

				<p>Other</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://www.uclass.psychol.ucl.ac.uk/">University College London Archive of Stuttered Speech (UCLASS)</a>
				</p>
				<p>
					<strong>Size: </strong>56 files 
					<br>
					<strong>Annotation: </strong>None
					<br>
					<strong>Licence: </strong>open access
				</p>
			</td>
			<td valign="top">
				English
			</td>
			<td valign="top">
				<p>This corpus consists of data from a study by <a href="https://www.uclass.psychol.ucl.ac.uk/Release2/hdbw.pdf ">Howell, Davis, Bartrip, and Wormald (2004)</a>.</p>
<p>The study looked at the fluency-enhancing effects of speaking at the same time as a frequency shifted version of the voice.</p>
<p>There were 14 speakers and four recording per speaker making 56 files in all. Recording are in SFS format.#SEThe four recordings for a speaker were for two texts and two readings of each text.</p>

				<p>For the relevant publication, see <a href="https://www.uclass.psychol.ucl.ac.uk/Release2/hdbw.pdf">Howell et al. (2004)</a></p>
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://www.uclass.psychol.ucl.ac.uk/uclassfsf.htm"><span class="fa fa-arrow-circle-o-down"></span>Download</a></p>

				<p>Other</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://osf.io/ygc8n/">Speech Exemplar and Evaluation Database (SEED)</a>
				</p>
				<p>
					<strong>Licence: </strong>Access by registration
				</p>
			</td>
			<td valign="top">
				English (American)
			</td>
			<td valign="top">
				<p>This corpus includes recordings of single words and continuous speech samples that provide examples of speakers with and without speech disorders. </p>

				<p>For the relevant publication, see <a href="https://www.tandfonline.com/doi/full/10.1080/02699206.2020.1743761">Atkins et al. (2020)</a></p>
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://osf.io/ygc8n/"><span class="fa fa-search"></span>Browse</a></p>

				<p>Other</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://www.seeingspeech.ac.uk/speechstar/child-speech-error-database/">STAR Child speech-error database</a>
				</p>
				<p>
					<strong>Size: </strong>162 audio files 
					<br>
					<strong>Annotation: </strong>orthographic, phonemic, phonetic
					<br>
					<strong>Licence: </strong>CC BY-NC-ND
				</p>
			</td>
			<td valign="top">
				English (Scottish)
			</td>
			<td valign="top">
				<p>This is a collection of multiple audio-articulatory speech disorder corpora</p>
<p>The corpus is constituted of composite videos containing (i) midsagittal tongue movement, imaged with ultrasound tongue imaging (UTI), (ii) optional profile lip movement, recorded with a headset-mounted camera, and (iii) synchronised audio.</p>
<p>Recordings in this database are of single words, or short phrases, produced by child speakers who were either reading orthographic stimuli from a screen, naming pictures, or repeating words produced by a researcher.  Phonemic transcriptions are provided in order that those who are not familiar with the (rhotic) central Scottish accent can be aware of the speech sound targets. </p>

				<p>For the relevant publication, see <a href="https://guarant.cz/icphs2023/236.pdf">Lawson et al. (2023)</a></p>
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://www.seeingspeech.ac.uk/speechstar/child-speech-error-database/?type=errorType&"><span class="fa fa-search"></span>Browse</a></p>

				<p>Other</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://www.seeingspeech.ac.uk/speechstar/disordered-child-speech-sentences-database/">STAR Disordered child-speech sentences database</a>
				</p>
				<p>
					<strong>Size: </strong>18 speakers
					<br>
					<strong>Annotation: </strong>orthographic, phonemic, phonetic
					<br>
					<strong>Licence: </strong>CC BY-NC-ND
				</p>
			</td>
			<td valign="top">
				English (Scottish)
			</td>
			<td valign="top">
				<p>This is a collection of multiple audio-articulatory speech-disorder corpora.</p>
<p>Database items are composite videos containing (i) midsagittal tongue movement, imaged with ultrasound tongue imaging (UTI), (ii) optional profile lip movement, recorded with a headset-mounted camera, and (iii) synchronised audio.</p>
<p>Recordings in this database are of sentences produced by child speakers (aged 6,1-13,4) who were either reading orthographic stimuli from a screen, or repeating sentences produced by a researcher. Diagnoses are based on clinicians' reports.</p>

				<p>For the relevant publication, see <a href="https://guarant.cz/icphs2023/236.pdf">Lawson et al. (2023)</a></p>
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://www.seeingspeech.ac.uk/speechstar/disordered-child-speech-sentences-database/"><span class="fa fa-search"></span>Browse</a></p>

				<p>Other</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://ultrasuite.github.io/data/cleft/">The Cleft Dataset</a>
				</p>
				<p>
					<strong>Size: </strong>11 speakers
					<br>
					<strong>Annotation: </strong>Orthographic, phonetic
					<br>
					<strong>Licence: </strong>open access
				</p>
			</td>
			<td valign="top">
				English (Scottish)
			</td>
			<td valign="top">
				<p>This is a corpus of ultrasound and audio recorded with children with cleft lip and palate. </p>

				<p>For the relevant publication, see <a href="https://doi.org/10.1159/000499753">Cleland et al. (2020)</a></p>
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://ultrasuite.github.io/download/"><span class="fa fa-arrow-circle-o-down"></span>Download</a></p>

				<p>Other</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://ultrasuite.github.io/data/uxssd/">Ultraphonix </a>
				</p>
				<p>
					<strong>Size: </strong>19 hours
					<br>
					<strong>Annotation: </strong>Orthographic, phonetic
					<br>
					<strong>Licence: </strong>open access
				</p>
			</td>
			<td valign="top">
				English (Scottish)
			</td>
			<td valign="top">
				<p>This is a corpus of ultrasound and audio recordings from children with speech sound disorders. It contains data from 20 speakers (16 male, 4 female), aged 6-13 years. </p>

				<p>For the relevant publication, see <a href="https://doi.org/10.48550/arXiv.1907.00835">Eshky et al. (2018)</a></p>
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://ultrasuite.github.io/download/"><span class="fa fa-arrow-circle-o-down"></span>Download</a></p>

				<p>Other</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://ultrasuite.github.io/data/ux2020/">Ultrax 2020 Dataset</a>
				</p>
				<p>
					<strong>Size: </strong>37 speakers
					<br>
					<strong>Annotation: </strong>Orthographic, phonetic
					<br>
					<strong>Licence: </strong>open access
				</p>
			</td>
			<td valign="top">
				English (Scottish)
			</td>
			<td valign="top">
				<p>This is a corpus of ultrasound tongue imaging and audio data, gathered from children with speech sound disorders by speech and language therapists in hospital environments.</p>
<p>11 female speakers and 26 male, aged 5-12 years. There is one recording per child.</p>
<p>The following metadata are available for each recording: speech waveform, raw ultrasound data, ultrasound parameters, and prompt text with date/time of utterance recording. </p>

				<p>For the relevant publication, see <a href="https://doi.org/10.48550/arXiv.1907.00835">Eshky et al. (2018)</a></p>
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://ultrasuite.github.io/download/"><span class="fa fa-arrow-circle-o-down"></span>Download</a></p>

				<p>Other</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://ultrasuite.github.io/data/uxssd/">Ultrax Speech Sound Disorders</a>
				</p>
				<p>
					<strong>Size: </strong>11 hours
					<br>
					<strong>Annotation: </strong>Orthographic, phonetic
					<br>
					<strong>Licence: </strong>open access
				</p>
			</td>
			<td valign="top">
				English (Scottish)
			</td>
			<td valign="top">
				<p>This is a corpus of ultrasound and audio recordings from children with speech sound disorders.</p>
<p>It contains data from 8 speakers (2 female and 6 male), aged 5-10 years. </p>

				<p>For the relevant publication, see <a href="https://doi.org/10.48550/arXiv.1907.00835">Eshky et al. (2018)</a></p>
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://ultrasuite.github.io/download/"><span class="fa fa-arrow-circle-o-down"></span>Download</a></p>

				<p>Other</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://phonodevelopment.sites.olt.ubc.ca/">Phonological Development Tools and Cross-Linguistic Phonologyt Project</a>
				</p>
				<p>
					<strong>Size: </strong>4 speakers for transcription resource
					<br>
					<strong>Annotation: </strong>Phonemic and phonetic transcription
					<br>
					<strong>Licence: </strong>CC 4.0 Non-commercial
				</p>
			</td>
			<td valign="top">
				English, French, Spanish, Mandarin, Cantonese, Slovenian
			</td>
			<td valign="top">
				<p>This corpus is used for investigating the phonological development across languages, and to evaluate intervention outcomes given a nonlinear phonological approach and ultrasound intervention outcomes across speech disorders.</p>

				
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://phonodevelopment.sites.olt.ubc.ca/"><span class="fa fa-search"></span>Browse</a></p>

				<p>Other</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://planv-project.gr/">Plan-V Aphasia Corpus</a>
				</p>
				<p>
					<strong>Size: </strong>1.84 MB
					<br>
					<strong>Annotation: </strong>Sentence, utterance, clause, POS
					<br>
					<strong>Licence: </strong>CC-BY 4.0
				</p>
			</td>
			<td valign="top">
				Greek (Modern)
			</td>
			<td valign="top">
				<p>This corpus contains spoken discourse data collected from Greek-speaking People with Aphasia (PWA) and from neurotypical adults.</p>

				<p>For the relevant publication, see <a href="https://doi.org/10.3389/fcomm.2023.919617">Stamouli et al. (2023)</a></p>
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://inventory.clarin.gr/corpus/1284"><span class="fa fa-arrow-circle-o-down"></span>Download</a></p>

				<p>Other</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://catalogue.elra.info/en-us/repository/browse/ELRA-S0489/">EWA DB Early Warning of Alzheimers speech database</a>
				</p>
				<p>
					<strong>Size: </strong>150 hours
					<br>
					<strong>Licence: </strong>Non-commercial and commercial options
				</p>
			</td>
			<td valign="top">
				Slovak
			</td>
			<td valign="top">
				<p>This corpus contains data from 3 clinical groups: Alzheimer's disease, Parkinson's disease, mild cognitive impairment, and a control group of healthy subjects.</p>
<p>Speech samples of each clinical group were obtained using the EWA smartphone application, which contains 4 different language tasks: sustained vowel phonation, diadochokinesis, object and action naming (30 objects and 30 actions), and picture description (two single pictures and three complex pictures).</p>

				
			</td>
			<td valign="top">
				
				<p>Other</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://catalog.elra.info/en-us/repository/browse/ELRA-S0413/">Ahoslabi-esophageal speech database</a>
				</p>
				<p>
					<strong>Size: </strong>10.8 hours
					<br>
					<strong>Licence: </strong>Non Commercial Use - ELRA END USER
				</p>
			</td>
			<td valign="top">
				Spanish, Castilian
			</td>
			<td valign="top">
				<p>This corpus primarily consists of recordings of 31 laryngectomees (27 males and 4 females) pronouncing 100 phonetically balanced sentences.</p>
<p>Esophageal voices were recorded in a soundproof recording cubicle with a Neuman microphone.</p>
<p>The corpus also includes parallel recordings of the  sentences by 9 healthy speakers (6 males and 3 females) to facilitate  speech processing tasks that require small parallel corpora, such as  voice conversion or synthetic speech adaptation. Apart from the  sentences, the database also contains 4 sustained vowels and a small set of isolated words (14) which can be very valuable for research on  esophageal speech analysis, diagnosis and evaluation. </p>

				<p>For the relevant publication, see <a href="https://doi.org/10.1016/j.csl.2020.101168">Serrano García (2021)</a></p>
			</td>
			<td valign="top">
				
				<p>Other</p>
			</td>
		</tr>
	</tbody>
	<tbody>
		<tr>
			<td valign="top">
				<p>
					<a href="https://catalog.ldc.upenn.edu/LDC2021S04">The SSNCE Database of Tamil Dysarthric Speech</a>
				</p>
				<p>
					<strong>Size: </strong>30 speakers
					<br>
					<strong>Annotation: </strong>phonetic
					<br>
					<strong>Licence: </strong><a href="https://catalog.ldc.upenn.edu/license/the-ssnce-database-of-tamil-dysarthric-speech-agreement.pdf">LDC</a>
				</p>
			</td>
			<td valign="top">
				Tamil
			</td>
			<td valign="top">
				<p>This is a corpus of Tamil Dysarthric Speech.</p>
<p> The corpus contains approximately eight hours of Tamil speech data, time-aligned transcripts and metadata collected from 30 speakers (20 dysarthric speakers and 10 non-dysarthric speakers).</p>
<p>The non-dysarthric speakers consisted of five female and five male subjects. The dysarthric speakers (7 female, 13 male) reported a diagnosis of cerebral palsy and ranged in age from 12 years old to 37 years ol.</p>
<p> In total, each speaker recorded 365 utterances consisting of single words and of sentences that included a combination of common and uncommon Tamil phrases.</p>
<p>The corpus includes time-aligned phonetic transcripts for all collected speech data. Additional documentation includes phoneme mappings and speaker metadata. Audio data is presented as 16-bit 16kHz FLAC compressed linear pcm wav. Transcripts are presented as UTF-8 encoded plain text.</p>

				
			</td>
			<td valign="top">
				<p><a class="btn btn-primary text-nowrap" href="https://catalog.ldc.upenn.edu/LDC2021S04"><span class="fa fa-arrow-circle-o-down"></span>Download</a></p>

				<p>Other</p>
			</td>
		</tr>
	</tbody>
</table>
